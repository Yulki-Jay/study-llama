4张显卡跑代码
node04               Mon Aug 28 19:59:26 2023  515.65.01
[0] NVIDIA A40       | 41'C,   0 % |   573 / 46068 MB |
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/jiangyunqi/anaconda3/envs/study-llama-v2-finetune/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
  warning_cache.warn(
开始加载模型
trainable params: 304,140 || all params: 109,786,380 || trainable%: 0.2770288992131811
PeftModelForSequenceClassification(
  (base_model): LoraModel(
    (model): BertForSequenceClassification(
      (bert): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0-11): 12 x BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(
                    in_features=768, out_features=768, bias=True
                    (lora_dropout): ModuleDict(
                      (default): Dropout(p=0.05, inplace=False)
                    )
                    (lora_A): ModuleDict(
                      (default): Linear(in_features=768, out_features=8, bias=False)
                    )
                    (lora_B): ModuleDict(
                      (default): Linear(in_features=8, out_features=768, bias=False)
                    )
                    (lora_embedding_A): ParameterDict()
                    (lora_embedding_B): ParameterDict()
                  )
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(
                    in_features=768, out_features=768, bias=True
                    (lora_dropout): ModuleDict(
                      (default): Dropout(p=0.05, inplace=False)
                    )
                    (lora_A): ModuleDict(
                      (default): Linear(in_features=768, out_features=8, bias=False)
                    )
                    (lora_B): ModuleDict(
                      (default): Linear(in_features=8, out_features=768, bias=False)
                    )
                    (lora_embedding_A): ParameterDict()
                    (lora_embedding_B): ParameterDict()
                  )
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
                (intermediate_act_fn): GELUActivation()
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
      (dropout): Dropout(p=0.1, inplace=False)
      (classifier): ModulesToSaveWrapper(
        (original_module): Linear(in_features=768, out_features=6, bias=True)
        (modules_to_save): ModuleDict(
          (default): Linear(in_features=768, out_features=6, bias=True)
        )
      )
    )
  )
)
MyBERTModel(
  (model): PeftModelForSequenceClassification(
    (base_model): LoraModel(
      (model): BertForSequenceClassification(
        (bert): BertModel(
          (embeddings): BertEmbeddings(
            (word_embeddings): Embedding(30522, 768, padding_idx=0)
            (position_embeddings): Embedding(512, 768)
            (token_type_embeddings): Embedding(2, 768)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder): BertEncoder(
            (layer): ModuleList(
              (0-11): 12 x BertLayer(
                (attention): BertAttention(
                  (self): BertSelfAttention(
                    (query): Linear(
                      in_features=768, out_features=768, bias=True
                      (lora_dropout): ModuleDict(
                        (default): Dropout(p=0.05, inplace=False)
                      )
                      (lora_A): ModuleDict(
                        (default): Linear(in_features=768, out_features=8, bias=False)
                      )
                      (lora_B): ModuleDict(
                        (default): Linear(in_features=8, out_features=768, bias=False)
                      )
                      (lora_embedding_A): ParameterDict()
                      (lora_embedding_B): ParameterDict()
                    )
                    (key): Linear(in_features=768, out_features=768, bias=True)
                    (value): Linear(
                      in_features=768, out_features=768, bias=True
                      (lora_dropout): ModuleDict(
                        (default): Dropout(p=0.05, inplace=False)
                      )
                      (lora_A): ModuleDict(
                        (default): Linear(in_features=768, out_features=8, bias=False)
                      )
                      (lora_B): ModuleDict(
                        (default): Linear(in_features=8, out_features=768, bias=False)
                      )
                      (lora_embedding_A): ParameterDict()
                      (lora_embedding_B): ParameterDict()
                    )
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (output): BertSelfOutput(
                    (dense): Linear(in_features=768, out_features=768, bias=True)
                    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
                (intermediate): BertIntermediate(
                  (dense): Linear(in_features=768, out_features=3072, bias=True)
                  (intermediate_act_fn): GELUActivation()
                )
                (output): BertOutput(
                  (dense): Linear(in_features=3072, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
          (pooler): BertPooler(
            (dense): Linear(in_features=768, out_features=768, bias=True)
            (activation): Tanh()
          )
        )
        (dropout): Dropout(p=0.1, inplace=False)
        (classifier): ModulesToSaveWrapper(
          (original_module): Linear(in_features=768, out_features=6, bias=True)
          (modules_to_save): ModuleDict(
            (default): Linear(in_features=768, out_features=6, bias=True)
          )
        )
      )
    )
  )
)
模型获取成功
**************************************************
数据开始加载
已经map了啊
数据加载成功
**************************************************
模型开始训练
You are using a CUDA device ('NVIDIA A40') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name  | Type                               | Params
-------------------------------------------------------------
0 | model | PeftModelForSequenceClassification | 109 M 
-------------------------------------------------------------
304 K     Trainable params
109 M     Non-trainable params
109 M     Total params
439.146   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
{'label': tensor(0), 'input_ids': tensor([  101,  1045,  2293,  2336,  1055,  3906,  6048,  2040,  2123,  1056,
         2514,  1996,  2342,  2000, 12873,  2091,  2477,  2005,  4268,   102,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}
/home/jiangyunqi/anaconda3/envs/study-llama-v2-finetune/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:486: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.
  rank_zero_warn(
/home/jiangyunqi/anaconda3/envs/study-llama-v2-finetune/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 72 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/jiangyunqi/anaconda3/envs/study-llama-v2-finetune/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 72 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/jiangyunqi/anaconda3/envs/study-llama-v2-finetune/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (31) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
Sanity Checking: 0it [00:00, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:01<00:01,  1.58s/it]Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]                                                                           Training: 0it [00:00, ?it/s]Training:   0%|          | 0/31 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/31 [00:00<?, ?it/s] Epoch 0:   3%|▎         | 1/31 [00:00<00:23,  1.27it/s]Epoch 0:   3%|▎         | 1/31 [00:01<00:42,  1.42s/it, v_num=10, train_loss_step=1.690, train_acc_step=0.338]Epoch 0:   6%|▋         | 2/31 [00:02<00:30,  1.05s/it, v_num=10, train_loss_step=1.690, train_acc_step=0.338]Epoch 0:   6%|▋         | 2/31 [00:02<00:39,  1.37s/it, v_num=10, train_loss_step=1.590, train_acc_step=0.350]Epoch 0:  10%|▉         | 3/31 [00:03<00:31,  1.14s/it, v_num=10, train_loss_step=1.590, train_acc_step=0.350]Epoch 0:  10%|▉         | 3/31 [00:04<00:37,  1.35s/it, v_num=10, train_loss_step=1.570, train_acc_step=0.350]Epoch 0:  13%|█▎        | 4/31 [00:04<00:31,  1.18s/it, v_num=10, train_loss_step=1.570, train_acc_step=0.350]Epoch 0:  13%|█▎        | 4/31 [00:05<00:36,  1.34s/it, v_num=10, train_loss_step=1.600, train_acc_step=0.348]Epoch 0:  16%|█▌        | 5/31 [00:06<00:31,  1.21s/it, v_num=10, train_loss_step=1.600, train_acc_step=0.348]Epoch 0:  16%|█▌        | 5/31 [00:06<00:34,  1.34s/it, v_num=10, train_loss_step=1.590, train_acc_step=0.340]Epoch 0:  19%|█▉        | 6/31 [00:07<00:30,  1.23s/it, v_num=10, train_loss_step=1.590, train_acc_step=0.340]Epoch 0:  19%|█▉        | 6/31 [00:08<00:33,  1.33s/it, v_num=10, train_loss_step=1.610, train_acc_step=0.316]Epoch 0:  23%|██▎       | 7/31 [00:08<00:29,  1.24s/it, v_num=10, train_loss_step=1.610, train_acc_step=0.316]Epoch 0:  23%|██▎       | 7/31 [00:09<00:31,  1.33s/it, v_num=10, train_loss_step=1.580, train_acc_step=0.363]Epoch 0:  26%|██▌       | 8/31 [00:10<00:28,  1.25s/it, v_num=10, train_loss_step=1.580, train_acc_step=0.363]Epoch 0:  26%|██▌       | 8/31 [00:10<00:30,  1.33s/it, v_num=10, train_loss_step=1.530, train_acc_step=0.387]Epoch 0:  29%|██▉       | 9/31 [00:11<00:27,  1.26s/it, v_num=10, train_loss_step=1.530, train_acc_step=0.387]Epoch 0:  29%|██▉       | 9/31 [00:11<00:29,  1.33s/it, v_num=10, train_loss_step=1.600, train_acc_step=0.367]Epoch 0:  32%|███▏      | 10/31 [00:12<00:26,  1.26s/it, v_num=10, train_loss_step=1.600, train_acc_step=0.367]Epoch 0:  32%|███▏      | 10/31 [00:13<00:27,  1.33s/it, v_num=10, train_loss_step=1.550, train_acc_step=0.379]Epoch 0:  35%|███▌      | 11/31 [00:13<00:25,  1.27s/it, v_num=10, train_loss_step=1.550, train_acc_step=0.379]Epoch 0:  35%|███▌      | 11/31 [00:14<00:26,  1.33s/it, v_num=10, train_loss_step=1.540, train_acc_step=0.414]Epoch 0:  39%|███▊      | 12/31 [00:15<00:24,  1.27s/it, v_num=10, train_loss_step=1.540, train_acc_step=0.414]Epoch 0:  39%|███▊      | 12/31 [00:15<00:25,  1.33s/it, v_num=10, train_loss_step=1.490, train_acc_step=0.426]Epoch 0:  42%|████▏     | 13/31 [00:16<00:23,  1.28s/it, v_num=10, train_loss_step=1.490, train_acc_step=0.426]Epoch 0:  42%|████▏     | 13/31 [00:17<00:23,  1.33s/it, v_num=10, train_loss_step=1.450, train_acc_step=0.447]Epoch 0:  45%|████▌     | 14/31 [00:17<00:21,  1.28s/it, v_num=10, train_loss_step=1.450, train_acc_step=0.447]Epoch 0:  45%|████▌     | 14/31 [00:18<00:22,  1.33s/it, v_num=10, train_loss_step=1.470, train_acc_step=0.457]Epoch 0:  48%|████▊     | 15/31 [00:19<00:20,  1.28s/it, v_num=10, train_loss_step=1.470, train_acc_step=0.457]Epoch 0:  48%|████▊     | 15/31 [00:19<00:21,  1.33s/it, v_num=10, train_loss_step=1.370, train_acc_step=0.504]Epoch 0:  52%|█████▏    | 16/31 [00:20<00:19,  1.29s/it, v_num=10, train_loss_step=1.370, train_acc_step=0.504]Epoch 0:  52%|█████▏    | 16/31 [00:21<00:19,  1.33s/it, v_num=10, train_loss_step=1.440, train_acc_step=0.469]Epoch 0:  55%|█████▍    | 17/31 [00:21<00:18,  1.29s/it, v_num=10, train_loss_step=1.440, train_acc_step=0.469]Epoch 0:  55%|█████▍    | 17/31 [00:22<00:18,  1.33s/it, v_num=10, train_loss_step=1.360, train_acc_step=0.492]Epoch 0:  58%|█████▊    | 18/31 [00:23<00:16,  1.29s/it, v_num=10, train_loss_step=1.360, train_acc_step=0.492]Epoch 0:  58%|█████▊    | 18/31 [00:23<00:17,  1.33s/it, v_num=10, train_loss_step=1.350, train_acc_step=0.508]Epoch 0:  61%|██████▏   | 19/31 [00:24<00:15,  1.29s/it, v_num=10, train_loss_step=1.350, train_acc_step=0.508]Epoch 0:  61%|██████▏   | 19/31 [00:25<00:15,  1.33s/it, v_num=10, train_loss_step=1.390, train_acc_step=0.484]Epoch 0:  65%|██████▍   | 20/31 [00:25<00:14,  1.29s/it, v_num=10, train_loss_step=1.390, train_acc_step=0.484]Epoch 0:  65%|██████▍   | 20/31 [00:26<00:14,  1.33s/it, v_num=10, train_loss_step=1.260, train_acc_step=0.553]Epoch 0:  68%|██████▊   | 21/31 [00:27<00:12,  1.30s/it, v_num=10, train_loss_step=1.260, train_acc_step=0.553]Epoch 0:  68%|██████▊   | 21/31 [00:27<00:13,  1.33s/it, v_num=10, train_loss_step=1.350, train_acc_step=0.508]Epoch 0:  71%|███████   | 22/31 [00:28<00:11,  1.30s/it, v_num=10, train_loss_step=1.350, train_acc_step=0.508]Epoch 0:  71%|███████   | 22/31 [00:29<00:11,  1.33s/it, v_num=10, train_loss_step=1.270, train_acc_step=0.545]Epoch 0:  74%|███████▍  | 23/31 [00:29<00:10,  1.30s/it, v_num=10, train_loss_step=1.270, train_acc_step=0.545]Epoch 0:  74%|███████▍  | 23/31 [00:30<00:10,  1.33s/it, v_num=10, train_loss_step=1.290, train_acc_step=0.502]Epoch 0:  77%|███████▋  | 24/31 [00:31<00:09,  1.30s/it, v_num=10, train_loss_step=1.290, train_acc_step=0.502]Epoch 0:  77%|███████▋  | 24/31 [00:31<00:09,  1.33s/it, v_num=10, train_loss_step=1.250, train_acc_step=0.531]Epoch 0:  81%|████████  | 25/31 [00:32<00:07,  1.30s/it, v_num=10, train_loss_step=1.250, train_acc_step=0.531]Epoch 0:  81%|████████  | 25/31 [00:33<00:07,  1.33s/it, v_num=10, train_loss_step=1.230, train_acc_step=0.539]Epoch 0:  84%|████████▍ | 26/31 [00:33<00:06,  1.30s/it, v_num=10, train_loss_step=1.230, train_acc_step=0.539]Epoch 0:  84%|████████▍ | 26/31 [00:34<00:06,  1.33s/it, v_num=10, train_loss_step=1.210, train_acc_step=0.543]Epoch 0:  87%|████████▋ | 27/31 [00:35<00:05,  1.30s/it, v_num=10, train_loss_step=1.210, train_acc_step=0.543]Epoch 0:  87%|████████▋ | 27/31 [00:35<00:05,  1.33s/it, v_num=10, train_loss_step=1.150, train_acc_step=0.564]Epoch 0:  90%|█████████ | 28/31 [00:36<00:03,  1.30s/it, v_num=10, train_loss_step=1.150, train_acc_step=0.564]Epoch 0:  90%|█████████ | 28/31 [00:37<00:03,  1.33s/it, v_num=10, train_loss_step=1.190, train_acc_step=0.539]Epoch 0:  94%|█████████▎| 29/31 [00:37<00:02,  1.31s/it, v_num=10, train_loss_step=1.190, train_acc_step=0.539]Epoch 0:  94%|█████████▎| 29/31 [00:38<00:02,  1.33s/it, v_num=10, train_loss_step=1.180, train_acc_step=0.557]Epoch 0:  97%|█████████▋| 30/31 [00:39<00:01,  1.31s/it, v_num=10, train_loss_step=1.180, train_acc_step=0.557]Epoch 0:  97%|█████████▋| 30/31 [00:39<00:01,  1.33s/it, v_num=10, train_loss_step=1.080, train_acc_step=0.584]Epoch 0: 100%|██████████| 31/31 [00:40<00:00,  1.31s/it, v_num=10, train_loss_step=1.080, train_acc_step=0.584]Epoch 0: 100%|██████████| 31/31 [00:41<00:00,  1.33s/it, v_num=10, train_loss_step=1.130, train_acc_step=0.578]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00,  2.02it/s][A
Validation DataLoader 0:  67%|██████▋   | 2/3 [00:00<00:00,  2.00it/s][A
Validation DataLoader 0: 100%|██████████| 3/3 [00:01<00:00,  2.00it/s][AEpoch 0: 100%|██████████| 31/31 [00:42<00:00,  1.38s/it, v_num=10, train_loss_step=1.130, train_acc_step=0.578, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586]
                                                                      [AEpoch 0: 100%|██████████| 31/31 [00:42<00:00,  1.38s/it, v_num=10, train_loss_step=1.130, train_acc_step=0.578, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 0:   0%|          | 0/31 [00:00<?, ?it/s, v_num=10, train_loss_step=1.130, train_acc_step=0.578, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]         Epoch 1:   0%|          | 0/31 [00:00<?, ?it/s, v_num=10, train_loss_step=1.130, train_acc_step=0.578, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:   3%|▎         | 1/31 [00:00<00:25,  1.20it/s, v_num=10, train_loss_step=1.130, train_acc_step=0.578, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:   3%|▎         | 1/31 [00:01<00:44,  1.48s/it, v_num=10, train_loss_step=1.140, train_acc_step=0.586, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:   6%|▋         | 2/31 [00:02<00:31,  1.08s/it, v_num=10, train_loss_step=1.140, train_acc_step=0.586, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:   6%|▋         | 2/31 [00:02<00:40,  1.41s/it, v_num=10, train_loss_step=1.090, train_acc_step=0.578, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  10%|▉         | 3/31 [00:03<00:32,  1.17s/it, v_num=10, train_loss_step=1.090, train_acc_step=0.578, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  10%|▉         | 3/31 [00:04<00:38,  1.38s/it, v_num=10, train_loss_step=1.080, train_acc_step=0.604, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  13%|█▎        | 4/31 [00:04<00:32,  1.21s/it, v_num=10, train_loss_step=1.080, train_acc_step=0.604, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  13%|█▎        | 4/31 [00:05<00:36,  1.37s/it, v_num=10, train_loss_step=1.050, train_acc_step=0.598, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  16%|█▌        | 5/31 [00:06<00:32,  1.23s/it, v_num=10, train_loss_step=1.050, train_acc_step=0.598, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  16%|█▌        | 5/31 [00:06<00:35,  1.36s/it, v_num=10, train_loss_step=1.060, train_acc_step=0.605, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  19%|█▉        | 6/31 [00:07<00:31,  1.25s/it, v_num=10, train_loss_step=1.060, train_acc_step=0.605, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  19%|█▉        | 6/31 [00:08<00:33,  1.36s/it, v_num=10, train_loss_step=1.050, train_acc_step=0.588, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  23%|██▎       | 7/31 [00:08<00:30,  1.26s/it, v_num=10, train_loss_step=1.050, train_acc_step=0.588, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  23%|██▎       | 7/31 [00:09<00:32,  1.36s/it, v_num=10, train_loss_step=1.020, train_acc_step=0.607, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  26%|██▌       | 8/31 [00:10<00:29,  1.27s/it, v_num=10, train_loss_step=1.020, train_acc_step=0.607, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  26%|██▌       | 8/31 [00:10<00:31,  1.35s/it, v_num=10, train_loss_step=1.060, train_acc_step=0.584, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  29%|██▉       | 9/31 [00:11<00:28,  1.28s/it, v_num=10, train_loss_step=1.060, train_acc_step=0.584, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  29%|██▉       | 9/31 [00:12<00:29,  1.35s/it, v_num=10, train_loss_step=1.010, train_acc_step=0.588, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  32%|███▏      | 10/31 [00:12<00:27,  1.29s/it, v_num=10, train_loss_step=1.010, train_acc_step=0.588, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  32%|███▏      | 10/31 [00:13<00:28,  1.35s/it, v_num=10, train_loss_step=1.060, train_acc_step=0.592, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  35%|███▌      | 11/31 [00:14<00:25,  1.29s/it, v_num=10, train_loss_step=1.060, train_acc_step=0.592, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  35%|███▌      | 11/31 [00:14<00:27,  1.35s/it, v_num=10, train_loss_step=1.050, train_acc_step=0.615, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  39%|███▊      | 12/31 [00:15<00:24,  1.30s/it, v_num=10, train_loss_step=1.050, train_acc_step=0.615, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  39%|███▊      | 12/31 [00:16<00:25,  1.35s/it, v_num=10, train_loss_step=0.987, train_acc_step=0.621, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  42%|████▏     | 13/31 [00:16<00:23,  1.30s/it, v_num=10, train_loss_step=0.987, train_acc_step=0.621, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  42%|████▏     | 13/31 [00:17<00:24,  1.35s/it, v_num=10, train_loss_step=0.953, train_acc_step=0.643, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  45%|████▌     | 14/31 [00:18<00:22,  1.30s/it, v_num=10, train_loss_step=0.953, train_acc_step=0.643, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  45%|████▌     | 14/31 [00:18<00:22,  1.35s/it, v_num=10, train_loss_step=0.904, train_acc_step=0.701, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  48%|████▊     | 15/31 [00:19<00:20,  1.31s/it, v_num=10, train_loss_step=0.904, train_acc_step=0.701, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  48%|████▊     | 15/31 [00:20<00:21,  1.35s/it, v_num=10, train_loss_step=0.854, train_acc_step=0.705, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  52%|█████▏    | 16/31 [00:20<00:19,  1.31s/it, v_num=10, train_loss_step=0.854, train_acc_step=0.705, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  52%|█████▏    | 16/31 [00:21<00:20,  1.35s/it, v_num=10, train_loss_step=0.905, train_acc_step=0.664, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  55%|█████▍    | 17/31 [00:22<00:18,  1.31s/it, v_num=10, train_loss_step=0.905, train_acc_step=0.664, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  55%|█████▍    | 17/31 [00:22<00:18,  1.35s/it, v_num=10, train_loss_step=0.858, train_acc_step=0.707, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  58%|█████▊    | 18/31 [00:23<00:17,  1.31s/it, v_num=10, train_loss_step=0.858, train_acc_step=0.707, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  58%|█████▊    | 18/31 [00:24<00:17,  1.35s/it, v_num=10, train_loss_step=0.915, train_acc_step=0.658, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  61%|██████▏   | 19/31 [00:24<00:15,  1.31s/it, v_num=10, train_loss_step=0.915, train_acc_step=0.658, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  61%|██████▏   | 19/31 [00:25<00:16,  1.35s/it, v_num=10, train_loss_step=0.797, train_acc_step=0.729, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  65%|██████▍   | 20/31 [00:26<00:14,  1.32s/it, v_num=10, train_loss_step=0.797, train_acc_step=0.729, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  65%|██████▍   | 20/31 [00:26<00:14,  1.35s/it, v_num=10, train_loss_step=0.831, train_acc_step=0.697, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  68%|██████▊   | 21/31 [00:27<00:13,  1.32s/it, v_num=10, train_loss_step=0.831, train_acc_step=0.697, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  68%|██████▊   | 21/31 [00:28<00:13,  1.35s/it, v_num=10, train_loss_step=0.686, train_acc_step=0.758, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  71%|███████   | 22/31 [00:29<00:11,  1.32s/it, v_num=10, train_loss_step=0.686, train_acc_step=0.758, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  71%|███████   | 22/31 [00:29<00:12,  1.35s/it, v_num=10, train_loss_step=0.780, train_acc_step=0.736, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  74%|███████▍  | 23/31 [00:30<00:10,  1.32s/it, v_num=10, train_loss_step=0.780, train_acc_step=0.736, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  74%|███████▍  | 23/31 [00:31<00:10,  1.35s/it, v_num=10, train_loss_step=0.755, train_acc_step=0.736, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  77%|███████▋  | 24/31 [00:31<00:09,  1.32s/it, v_num=10, train_loss_step=0.755, train_acc_step=0.736, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  77%|███████▋  | 24/31 [00:32<00:09,  1.35s/it, v_num=10, train_loss_step=0.719, train_acc_step=0.717, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  81%|████████  | 25/31 [00:33<00:07,  1.32s/it, v_num=10, train_loss_step=0.719, train_acc_step=0.717, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  81%|████████  | 25/31 [00:33<00:08,  1.35s/it, v_num=10, train_loss_step=0.712, train_acc_step=0.727, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  84%|████████▍ | 26/31 [00:34<00:06,  1.32s/it, v_num=10, train_loss_step=0.712, train_acc_step=0.727, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  84%|████████▍ | 26/31 [00:35<00:06,  1.35s/it, v_num=10, train_loss_step=0.745, train_acc_step=0.711, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  87%|████████▋ | 27/31 [00:35<00:05,  1.32s/it, v_num=10, train_loss_step=0.745, train_acc_step=0.711, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  87%|████████▋ | 27/31 [00:36<00:05,  1.35s/it, v_num=10, train_loss_step=0.729, train_acc_step=0.727, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  90%|█████████ | 28/31 [00:37<00:03,  1.33s/it, v_num=10, train_loss_step=0.729, train_acc_step=0.727, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  90%|█████████ | 28/31 [00:37<00:04,  1.35s/it, v_num=10, train_loss_step=0.681, train_acc_step=0.756, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  94%|█████████▎| 29/31 [00:38<00:02,  1.33s/it, v_num=10, train_loss_step=0.681, train_acc_step=0.756, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  94%|█████████▎| 29/31 [00:39<00:02,  1.35s/it, v_num=10, train_loss_step=0.658, train_acc_step=0.771, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  97%|█████████▋| 30/31 [00:39<00:01,  1.33s/it, v_num=10, train_loss_step=0.658, train_acc_step=0.771, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1:  97%|█████████▋| 30/31 [00:40<00:01,  1.35s/it, v_num=10, train_loss_step=0.614, train_acc_step=0.799, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1: 100%|██████████| 31/31 [00:41<00:00,  1.33s/it, v_num=10, train_loss_step=0.614, train_acc_step=0.799, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]Epoch 1: 100%|██████████| 31/31 [00:41<00:00,  1.35s/it, v_num=10, train_loss_step=0.681, train_acc_step=0.752, val_loss_step=1.060, val_acc_step=0.602, val_loss_epoch=1.080, val_acc_epoch=0.586, train_loss_epoch=1.400, train_acc_epoch=0.461]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:01,  1.98it/s][A
Validation DataLoader 0:  67%|██████▋   | 2/3 [00:01<00:00,  1.97it/s][A
Validation DataLoader 0: 100%|██████████| 3/3 [00:01<00:00,  1.97it/s][AEpoch 1: 100%|██████████| 31/31 [00:43<00:00,  1.40s/it, v_num=10, train_loss_step=0.681, train_acc_step=0.752, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=1.400, train_acc_epoch=0.461]
                                                                      [AEpoch 1: 100%|██████████| 31/31 [00:43<00:00,  1.40s/it, v_num=10, train_loss_step=0.681, train_acc_step=0.752, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 1:   0%|          | 0/31 [00:00<?, ?it/s, v_num=10, train_loss_step=0.681, train_acc_step=0.752, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]         Epoch 2:   0%|          | 0/31 [00:00<?, ?it/s, v_num=10, train_loss_step=0.681, train_acc_step=0.752, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:   3%|▎         | 1/31 [00:00<00:26,  1.12it/s, v_num=10, train_loss_step=0.681, train_acc_step=0.752, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:   3%|▎         | 1/31 [00:01<00:46,  1.54s/it, v_num=10, train_loss_step=0.601, train_acc_step=0.795, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:   6%|▋         | 2/31 [00:02<00:32,  1.12s/it, v_num=10, train_loss_step=0.601, train_acc_step=0.795, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:   6%|▋         | 2/31 [00:02<00:41,  1.45s/it, v_num=10, train_loss_step=0.621, train_acc_step=0.779, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  10%|▉         | 3/31 [00:03<00:33,  1.20s/it, v_num=10, train_loss_step=0.621, train_acc_step=0.779, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  10%|▉         | 3/31 [00:04<00:39,  1.42s/it, v_num=10, train_loss_step=0.570, train_acc_step=0.785, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  13%|█▎        | 4/31 [00:04<00:33,  1.24s/it, v_num=10, train_loss_step=0.570, train_acc_step=0.785, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  13%|█▎        | 4/31 [00:05<00:37,  1.40s/it, v_num=10, train_loss_step=0.510, train_acc_step=0.824, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  16%|█▌        | 5/31 [00:06<00:32,  1.26s/it, v_num=10, train_loss_step=0.510, train_acc_step=0.824, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  16%|█▌        | 5/31 [00:06<00:36,  1.39s/it, v_num=10, train_loss_step=0.481, train_acc_step=0.830, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  19%|█▉        | 6/31 [00:07<00:31,  1.28s/it, v_num=10, train_loss_step=0.481, train_acc_step=0.830, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  19%|█▉        | 6/31 [00:08<00:34,  1.39s/it, v_num=10, train_loss_step=0.523, train_acc_step=0.828, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  23%|██▎       | 7/31 [00:09<00:30,  1.29s/it, v_num=10, train_loss_step=0.523, train_acc_step=0.828, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  23%|██▎       | 7/31 [00:09<00:33,  1.38s/it, v_num=10, train_loss_step=0.520, train_acc_step=0.805, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  26%|██▌       | 8/31 [00:10<00:29,  1.30s/it, v_num=10, train_loss_step=0.520, train_acc_step=0.805, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  26%|██▌       | 8/31 [00:11<00:31,  1.38s/it, v_num=10, train_loss_step=0.567, train_acc_step=0.809, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  29%|██▉       | 9/31 [00:11<00:28,  1.30s/it, v_num=10, train_loss_step=0.567, train_acc_step=0.809, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  29%|██▉       | 9/31 [00:12<00:30,  1.38s/it, v_num=10, train_loss_step=0.499, train_acc_step=0.834, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  32%|███▏      | 10/31 [00:13<00:27,  1.31s/it, v_num=10, train_loss_step=0.499, train_acc_step=0.834, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  32%|███▏      | 10/31 [00:13<00:28,  1.37s/it, v_num=10, train_loss_step=0.458, train_acc_step=0.832, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  35%|███▌      | 11/31 [00:14<00:26,  1.31s/it, v_num=10, train_loss_step=0.458, train_acc_step=0.832, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  35%|███▌      | 11/31 [00:15<00:27,  1.37s/it, v_num=10, train_loss_step=0.509, train_acc_step=0.820, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  39%|███▊      | 12/31 [00:15<00:25,  1.32s/it, v_num=10, train_loss_step=0.509, train_acc_step=0.820, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  39%|███▊      | 12/31 [00:16<00:26,  1.37s/it, v_num=10, train_loss_step=0.526, train_acc_step=0.814, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  42%|████▏     | 13/31 [00:17<00:23,  1.32s/it, v_num=10, train_loss_step=0.526, train_acc_step=0.814, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  42%|████▏     | 13/31 [00:17<00:24,  1.37s/it, v_num=10, train_loss_step=0.450, train_acc_step=0.844, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  45%|████▌     | 14/31 [00:18<00:22,  1.32s/it, v_num=10, train_loss_step=0.450, train_acc_step=0.844, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  45%|████▌     | 14/31 [00:19<00:23,  1.37s/it, v_num=10, train_loss_step=0.517, train_acc_step=0.832, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  48%|████▊     | 15/31 [00:19<00:21,  1.32s/it, v_num=10, train_loss_step=0.517, train_acc_step=0.832, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  48%|████▊     | 15/31 [00:20<00:21,  1.37s/it, v_num=10, train_loss_step=0.491, train_acc_step=0.836, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  52%|█████▏    | 16/31 [00:21<00:19,  1.33s/it, v_num=10, train_loss_step=0.491, train_acc_step=0.836, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  52%|█████▏    | 16/31 [00:21<00:20,  1.37s/it, v_num=10, train_loss_step=0.423, train_acc_step=0.848, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  55%|█████▍    | 17/31 [00:22<00:18,  1.33s/it, v_num=10, train_loss_step=0.423, train_acc_step=0.848, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  55%|█████▍    | 17/31 [00:23<00:19,  1.37s/it, v_num=10, train_loss_step=0.548, train_acc_step=0.818, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  58%|█████▊    | 18/31 [00:23<00:17,  1.33s/it, v_num=10, train_loss_step=0.548, train_acc_step=0.818, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  58%|█████▊    | 18/31 [00:24<00:17,  1.37s/it, v_num=10, train_loss_step=0.434, train_acc_step=0.846, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  61%|██████▏   | 19/31 [00:25<00:15,  1.33s/it, v_num=10, train_loss_step=0.434, train_acc_step=0.846, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  61%|██████▏   | 19/31 [00:25<00:16,  1.37s/it, v_num=10, train_loss_step=0.425, train_acc_step=0.826, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  65%|██████▍   | 20/31 [00:26<00:14,  1.33s/it, v_num=10, train_loss_step=0.425, train_acc_step=0.826, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  65%|██████▍   | 20/31 [00:27<00:15,  1.37s/it, v_num=10, train_loss_step=0.459, train_acc_step=0.814, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  68%|██████▊   | 21/31 [00:28<00:13,  1.33s/it, v_num=10, train_loss_step=0.459, train_acc_step=0.814, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  68%|██████▊   | 21/31 [00:28<00:13,  1.37s/it, v_num=10, train_loss_step=0.387, train_acc_step=0.859, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  71%|███████   | 22/31 [00:29<00:12,  1.34s/it, v_num=10, train_loss_step=0.387, train_acc_step=0.859, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  71%|███████   | 22/31 [00:30<00:12,  1.37s/it, v_num=10, train_loss_step=0.381, train_acc_step=0.855, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  74%|███████▍  | 23/31 [00:30<00:10,  1.34s/it, v_num=10, train_loss_step=0.381, train_acc_step=0.855, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  74%|███████▍  | 23/31 [00:31<00:10,  1.36s/it, v_num=10, train_loss_step=0.354, train_acc_step=0.869, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  77%|███████▋  | 24/31 [00:32<00:09,  1.34s/it, v_num=10, train_loss_step=0.354, train_acc_step=0.869, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  77%|███████▋  | 24/31 [00:32<00:09,  1.37s/it, v_num=10, train_loss_step=0.400, train_acc_step=0.855, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  81%|████████  | 25/31 [00:33<00:08,  1.34s/it, v_num=10, train_loss_step=0.400, train_acc_step=0.855, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  81%|████████  | 25/31 [00:34<00:08,  1.36s/it, v_num=10, train_loss_step=0.360, train_acc_step=0.873, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  84%|████████▍ | 26/31 [00:34<00:06,  1.34s/it, v_num=10, train_loss_step=0.360, train_acc_step=0.873, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  84%|████████▍ | 26/31 [00:35<00:06,  1.36s/it, v_num=10, train_loss_step=0.403, train_acc_step=0.844, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  87%|████████▋ | 27/31 [00:36<00:05,  1.34s/it, v_num=10, train_loss_step=0.403, train_acc_step=0.844, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  87%|████████▋ | 27/31 [00:36<00:05,  1.36s/it, v_num=10, train_loss_step=0.341, train_acc_step=0.875, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  90%|█████████ | 28/31 [00:37<00:04,  1.34s/it, v_num=10, train_loss_step=0.341, train_acc_step=0.875, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  90%|█████████ | 28/31 [00:38<00:04,  1.36s/it, v_num=10, train_loss_step=0.349, train_acc_step=0.875, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  94%|█████████▎| 29/31 [00:38<00:02,  1.34s/it, v_num=10, train_loss_step=0.349, train_acc_step=0.875, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  94%|█████████▎| 29/31 [00:39<00:02,  1.36s/it, v_num=10, train_loss_step=0.366, train_acc_step=0.873, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  97%|█████████▋| 30/31 [00:40<00:01,  1.34s/it, v_num=10, train_loss_step=0.366, train_acc_step=0.873, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2:  97%|█████████▋| 30/31 [00:40<00:01,  1.36s/it, v_num=10, train_loss_step=0.339, train_acc_step=0.875, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2: 100%|██████████| 31/31 [00:41<00:00,  1.34s/it, v_num=10, train_loss_step=0.339, train_acc_step=0.875, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]Epoch 2: 100%|██████████| 31/31 [00:42<00:00,  1.36s/it, v_num=10, train_loss_step=0.318, train_acc_step=0.900, val_loss_step=0.516, val_acc_step=0.820, val_loss_epoch=0.559, val_acc_epoch=0.800, train_loss_epoch=0.885, train_acc_epoch=0.673]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:01,  1.96it/s][A
Validation DataLoader 0:  67%|██████▋   | 2/3 [00:01<00:00,  1.95it/s][A
Validation DataLoader 0: 100%|██████████| 3/3 [00:01<00:00,  1.95it/s][AEpoch 2: 100%|██████████| 31/31 [00:43<00:00,  1.42s/it, v_num=10, train_loss_step=0.318, train_acc_step=0.900, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.885, train_acc_epoch=0.673]
                                                                      [AEpoch 2: 100%|██████████| 31/31 [00:43<00:00,  1.42s/it, v_num=10, train_loss_step=0.318, train_acc_step=0.900, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 2:   0%|          | 0/31 [00:00<?, ?it/s, v_num=10, train_loss_step=0.318, train_acc_step=0.900, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]         Epoch 3:   0%|          | 0/31 [00:00<?, ?it/s, v_num=10, train_loss_step=0.318, train_acc_step=0.900, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:   3%|▎         | 1/31 [00:00<00:25,  1.17it/s, v_num=10, train_loss_step=0.318, train_acc_step=0.900, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:   3%|▎         | 1/31 [00:01<00:45,  1.51s/it, v_num=10, train_loss_step=0.269, train_acc_step=0.904, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:   6%|▋         | 2/31 [00:02<00:32,  1.11s/it, v_num=10, train_loss_step=0.269, train_acc_step=0.904, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:   6%|▋         | 2/31 [00:02<00:41,  1.43s/it, v_num=10, train_loss_step=0.326, train_acc_step=0.883, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  10%|▉         | 3/31 [00:03<00:33,  1.19s/it, v_num=10, train_loss_step=0.326, train_acc_step=0.883, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  10%|▉         | 3/31 [00:04<00:39,  1.41s/it, v_num=10, train_loss_step=0.317, train_acc_step=0.885, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  13%|█▎        | 4/31 [00:04<00:33,  1.23s/it, v_num=10, train_loss_step=0.317, train_acc_step=0.885, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  13%|█▎        | 4/31 [00:05<00:37,  1.40s/it, v_num=10, train_loss_step=0.296, train_acc_step=0.896, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  16%|█▌        | 5/31 [00:06<00:32,  1.26s/it, v_num=10, train_loss_step=0.296, train_acc_step=0.896, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  16%|█▌        | 5/31 [00:06<00:36,  1.39s/it, v_num=10, train_loss_step=0.258, train_acc_step=0.904, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  19%|█▉        | 6/31 [00:07<00:31,  1.28s/it, v_num=10, train_loss_step=0.258, train_acc_step=0.904, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  19%|█▉        | 6/31 [00:08<00:34,  1.38s/it, v_num=10, train_loss_step=0.295, train_acc_step=0.881, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  23%|██▎       | 7/31 [00:09<00:30,  1.29s/it, v_num=10, train_loss_step=0.295, train_acc_step=0.881, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  23%|██▎       | 7/31 [00:09<00:33,  1.38s/it, v_num=10, train_loss_step=0.259, train_acc_step=0.896, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  26%|██▌       | 8/31 [00:10<00:29,  1.30s/it, v_num=10, train_loss_step=0.259, train_acc_step=0.896, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  26%|██▌       | 8/31 [00:11<00:31,  1.38s/it, v_num=10, train_loss_step=0.271, train_acc_step=0.896, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  29%|██▉       | 9/31 [00:11<00:28,  1.30s/it, v_num=10, train_loss_step=0.271, train_acc_step=0.896, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  29%|██▉       | 9/31 [00:12<00:30,  1.38s/it, v_num=10, train_loss_step=0.273, train_acc_step=0.902, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  32%|███▏      | 10/31 [00:13<00:27,  1.31s/it, v_num=10, train_loss_step=0.273, train_acc_step=0.902, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  32%|███▏      | 10/31 [00:13<00:28,  1.38s/it, v_num=10, train_loss_step=0.265, train_acc_step=0.898, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  35%|███▌      | 11/31 [00:14<00:26,  1.32s/it, v_num=10, train_loss_step=0.265, train_acc_step=0.898, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  35%|███▌      | 11/31 [00:15<00:27,  1.37s/it, v_num=10, train_loss_step=0.324, train_acc_step=0.871, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  39%|███▊      | 12/31 [00:15<00:25,  1.32s/it, v_num=10, train_loss_step=0.324, train_acc_step=0.871, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  39%|███▊      | 12/31 [00:16<00:26,  1.37s/it, v_num=10, train_loss_step=0.250, train_acc_step=0.898, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  42%|████▏     | 13/31 [00:17<00:23,  1.32s/it, v_num=10, train_loss_step=0.250, train_acc_step=0.898, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  42%|████▏     | 13/31 [00:17<00:24,  1.37s/it, v_num=10, train_loss_step=0.301, train_acc_step=0.881, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  45%|████▌     | 14/31 [00:18<00:22,  1.33s/it, v_num=10, train_loss_step=0.301, train_acc_step=0.881, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  45%|████▌     | 14/31 [00:19<00:23,  1.37s/it, v_num=10, train_loss_step=0.268, train_acc_step=0.898, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  48%|████▊     | 15/31 [00:19<00:21,  1.33s/it, v_num=10, train_loss_step=0.268, train_acc_step=0.898, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  48%|████▊     | 15/31 [00:20<00:21,  1.37s/it, v_num=10, train_loss_step=0.212, train_acc_step=0.922, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  52%|█████▏    | 16/31 [00:21<00:19,  1.33s/it, v_num=10, train_loss_step=0.212, train_acc_step=0.922, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  52%|█████▏    | 16/31 [00:21<00:20,  1.37s/it, v_num=10, train_loss_step=0.298, train_acc_step=0.900, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  55%|█████▍    | 17/31 [00:22<00:18,  1.33s/it, v_num=10, train_loss_step=0.298, train_acc_step=0.900, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  55%|█████▍    | 17/31 [00:23<00:19,  1.37s/it, v_num=10, train_loss_step=0.203, train_acc_step=0.926, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  58%|█████▊    | 18/31 [00:24<00:17,  1.33s/it, v_num=10, train_loss_step=0.203, train_acc_step=0.926, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  58%|█████▊    | 18/31 [00:24<00:17,  1.37s/it, v_num=10, train_loss_step=0.284, train_acc_step=0.896, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  61%|██████▏   | 19/31 [00:25<00:16,  1.34s/it, v_num=10, train_loss_step=0.284, train_acc_step=0.896, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  61%|██████▏   | 19/31 [00:26<00:16,  1.37s/it, v_num=10, train_loss_step=0.297, train_acc_step=0.900, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  65%|██████▍   | 20/31 [00:26<00:14,  1.34s/it, v_num=10, train_loss_step=0.297, train_acc_step=0.900, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  65%|██████▍   | 20/31 [00:27<00:15,  1.37s/it, v_num=10, train_loss_step=0.268, train_acc_step=0.902, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  68%|██████▊   | 21/31 [00:28<00:13,  1.34s/it, v_num=10, train_loss_step=0.268, train_acc_step=0.902, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  68%|██████▊   | 21/31 [00:28<00:13,  1.37s/it, v_num=10, train_loss_step=0.249, train_acc_step=0.922, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  71%|███████   | 22/31 [00:29<00:12,  1.34s/it, v_num=10, train_loss_step=0.249, train_acc_step=0.922, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  71%|███████   | 22/31 [00:30<00:12,  1.37s/it, v_num=10, train_loss_step=0.246, train_acc_step=0.906, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  74%|███████▍  | 23/31 [00:30<00:10,  1.34s/it, v_num=10, train_loss_step=0.246, train_acc_step=0.906, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  74%|███████▍  | 23/31 [00:31<00:10,  1.37s/it, v_num=10, train_loss_step=0.216, train_acc_step=0.912, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  77%|███████▋  | 24/31 [00:32<00:09,  1.34s/it, v_num=10, train_loss_step=0.216, train_acc_step=0.912, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  77%|███████▋  | 24/31 [00:32<00:09,  1.37s/it, v_num=10, train_loss_step=0.193, train_acc_step=0.928, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  81%|████████  | 25/31 [00:33<00:08,  1.34s/it, v_num=10, train_loss_step=0.193, train_acc_step=0.928, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  81%|████████  | 25/31 [00:34<00:08,  1.37s/it, v_num=10, train_loss_step=0.231, train_acc_step=0.918, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  84%|████████▍ | 26/31 [00:34<00:06,  1.34s/it, v_num=10, train_loss_step=0.231, train_acc_step=0.918, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  84%|████████▍ | 26/31 [00:35<00:06,  1.37s/it, v_num=10, train_loss_step=0.229, train_acc_step=0.916, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  87%|████████▋ | 27/31 [00:36<00:05,  1.35s/it, v_num=10, train_loss_step=0.229, train_acc_step=0.916, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  87%|████████▋ | 27/31 [00:36<00:05,  1.37s/it, v_num=10, train_loss_step=0.243, train_acc_step=0.906, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  90%|█████████ | 28/31 [00:37<00:04,  1.35s/it, v_num=10, train_loss_step=0.243, train_acc_step=0.906, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  90%|█████████ | 28/31 [00:38<00:04,  1.37s/it, v_num=10, train_loss_step=0.237, train_acc_step=0.916, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  94%|█████████▎| 29/31 [00:39<00:02,  1.35s/it, v_num=10, train_loss_step=0.237, train_acc_step=0.916, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  94%|█████████▎| 29/31 [00:39<00:02,  1.37s/it, v_num=10, train_loss_step=0.229, train_acc_step=0.906, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  97%|█████████▋| 30/31 [00:40<00:01,  1.35s/it, v_num=10, train_loss_step=0.229, train_acc_step=0.906, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3:  97%|█████████▋| 30/31 [00:41<00:01,  1.37s/it, v_num=10, train_loss_step=0.249, train_acc_step=0.916, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3: 100%|██████████| 31/31 [00:41<00:00,  1.35s/it, v_num=10, train_loss_step=0.249, train_acc_step=0.916, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]Epoch 3: 100%|██████████| 31/31 [00:42<00:00,  1.37s/it, v_num=10, train_loss_step=0.200, train_acc_step=0.932, val_loss_step=0.298, val_acc_step=0.893, val_loss_epoch=0.293, val_acc_epoch=0.904, train_loss_epoch=0.456, train_acc_epoch=0.838]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:01,  1.97it/s][A
Validation DataLoader 0:  67%|██████▋   | 2/3 [00:01<00:00,  1.94it/s][A
Validation DataLoader 0: 100%|██████████| 3/3 [00:01<00:00,  1.94it/s][AEpoch 3: 100%|██████████| 31/31 [00:44<00:00,  1.43s/it, v_num=10, train_loss_step=0.200, train_acc_step=0.932, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.456, train_acc_epoch=0.838]
                                                                      [AEpoch 3: 100%|██████████| 31/31 [00:44<00:00,  1.43s/it, v_num=10, train_loss_step=0.200, train_acc_step=0.932, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 3:   0%|          | 0/31 [00:00<?, ?it/s, v_num=10, train_loss_step=0.200, train_acc_step=0.932, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]         Epoch 4:   0%|          | 0/31 [00:00<?, ?it/s, v_num=10, train_loss_step=0.200, train_acc_step=0.932, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:   3%|▎         | 1/31 [00:00<00:25,  1.18it/s, v_num=10, train_loss_step=0.200, train_acc_step=0.932, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:   3%|▎         | 1/31 [00:01<00:45,  1.50s/it, v_num=10, train_loss_step=0.225, train_acc_step=0.922, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:   6%|▋         | 2/31 [00:02<00:32,  1.11s/it, v_num=10, train_loss_step=0.225, train_acc_step=0.922, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:   6%|▋         | 2/31 [00:02<00:41,  1.43s/it, v_num=10, train_loss_step=0.201, train_acc_step=0.930, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  10%|▉         | 3/31 [00:03<00:33,  1.19s/it, v_num=10, train_loss_step=0.201, train_acc_step=0.930, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  10%|▉         | 3/31 [00:04<00:39,  1.41s/it, v_num=10, train_loss_step=0.205, train_acc_step=0.932, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  13%|█▎        | 4/31 [00:04<00:33,  1.24s/it, v_num=10, train_loss_step=0.205, train_acc_step=0.932, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  13%|█▎        | 4/31 [00:05<00:37,  1.40s/it, v_num=10, train_loss_step=0.216, train_acc_step=0.924, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  16%|█▌        | 5/31 [00:06<00:32,  1.26s/it, v_num=10, train_loss_step=0.216, train_acc_step=0.924, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  16%|█▌        | 5/31 [00:06<00:36,  1.40s/it, v_num=10, train_loss_step=0.238, train_acc_step=0.924, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  19%|█▉        | 6/31 [00:07<00:32,  1.28s/it, v_num=10, train_loss_step=0.238, train_acc_step=0.924, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  19%|█▉        | 6/31 [00:08<00:34,  1.39s/it, v_num=10, train_loss_step=0.172, train_acc_step=0.936, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  23%|██▎       | 7/31 [00:09<00:31,  1.30s/it, v_num=10, train_loss_step=0.172, train_acc_step=0.936, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  23%|██▎       | 7/31 [00:09<00:33,  1.39s/it, v_num=10, train_loss_step=0.242, train_acc_step=0.908, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  26%|██▌       | 8/31 [00:10<00:30,  1.31s/it, v_num=10, train_loss_step=0.242, train_acc_step=0.908, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  26%|██▌       | 8/31 [00:11<00:31,  1.39s/it, v_num=10, train_loss_step=0.212, train_acc_step=0.924, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  29%|██▉       | 9/31 [00:11<00:28,  1.31s/it, v_num=10, train_loss_step=0.212, train_acc_step=0.924, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  29%|██▉       | 9/31 [00:12<00:30,  1.39s/it, v_num=10, train_loss_step=0.165, train_acc_step=0.936, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  32%|███▏      | 10/31 [00:13<00:27,  1.32s/it, v_num=10, train_loss_step=0.165, train_acc_step=0.936, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  32%|███▏      | 10/31 [00:13<00:29,  1.39s/it, v_num=10, train_loss_step=0.170, train_acc_step=0.936, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  35%|███▌      | 11/31 [00:14<00:26,  1.33s/it, v_num=10, train_loss_step=0.170, train_acc_step=0.936, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  35%|███▌      | 11/31 [00:15<00:27,  1.39s/it, v_num=10, train_loss_step=0.196, train_acc_step=0.928, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  39%|███▊      | 12/31 [00:15<00:25,  1.33s/it, v_num=10, train_loss_step=0.196, train_acc_step=0.928, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  39%|███▊      | 12/31 [00:16<00:26,  1.38s/it, v_num=10, train_loss_step=0.261, train_acc_step=0.914, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  42%|████▏     | 13/31 [00:17<00:23,  1.33s/it, v_num=10, train_loss_step=0.261, train_acc_step=0.914, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  42%|████▏     | 13/31 [00:17<00:24,  1.38s/it, v_num=10, train_loss_step=0.190, train_acc_step=0.924, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  45%|████▌     | 14/31 [00:18<00:22,  1.34s/it, v_num=10, train_loss_step=0.190, train_acc_step=0.924, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  45%|████▌     | 14/31 [00:19<00:23,  1.38s/it, v_num=10, train_loss_step=0.199, train_acc_step=0.928, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  48%|████▊     | 15/31 [00:20<00:21,  1.34s/it, v_num=10, train_loss_step=0.199, train_acc_step=0.928, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  48%|████▊     | 15/31 [00:20<00:22,  1.38s/it, v_num=10, train_loss_step=0.206, train_acc_step=0.934, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  52%|█████▏    | 16/31 [00:21<00:20,  1.34s/it, v_num=10, train_loss_step=0.206, train_acc_step=0.934, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  52%|█████▏    | 16/31 [00:22<00:20,  1.38s/it, v_num=10, train_loss_step=0.210, train_acc_step=0.922, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  55%|█████▍    | 17/31 [00:22<00:18,  1.34s/it, v_num=10, train_loss_step=0.210, train_acc_step=0.922, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  55%|█████▍    | 17/31 [00:23<00:19,  1.38s/it, v_num=10, train_loss_step=0.207, train_acc_step=0.918, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  58%|█████▊    | 18/31 [00:24<00:17,  1.35s/it, v_num=10, train_loss_step=0.207, train_acc_step=0.918, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  58%|█████▊    | 18/31 [00:24<00:17,  1.38s/it, v_num=10, train_loss_step=0.160, train_acc_step=0.941, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  61%|██████▏   | 19/31 [00:25<00:16,  1.35s/it, v_num=10, train_loss_step=0.160, train_acc_step=0.941, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  61%|██████▏   | 19/31 [00:26<00:16,  1.38s/it, v_num=10, train_loss_step=0.170, train_acc_step=0.936, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  65%|██████▍   | 20/31 [00:26<00:14,  1.35s/it, v_num=10, train_loss_step=0.170, train_acc_step=0.936, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  65%|██████▍   | 20/31 [00:27<00:15,  1.38s/it, v_num=10, train_loss_step=0.180, train_acc_step=0.928, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  68%|██████▊   | 21/31 [00:28<00:13,  1.35s/it, v_num=10, train_loss_step=0.180, train_acc_step=0.928, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  68%|██████▊   | 21/31 [00:29<00:13,  1.38s/it, v_num=10, train_loss_step=0.169, train_acc_step=0.934, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  71%|███████   | 22/31 [00:29<00:12,  1.35s/it, v_num=10, train_loss_step=0.169, train_acc_step=0.934, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  71%|███████   | 22/31 [00:30<00:12,  1.38s/it, v_num=10, train_loss_step=0.215, train_acc_step=0.918, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  74%|███████▍  | 23/31 [00:31<00:10,  1.35s/it, v_num=10, train_loss_step=0.215, train_acc_step=0.918, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  74%|███████▍  | 23/31 [00:31<00:11,  1.38s/it, v_num=10, train_loss_step=0.154, train_acc_step=0.939, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  77%|███████▋  | 24/31 [00:32<00:09,  1.35s/it, v_num=10, train_loss_step=0.154, train_acc_step=0.939, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  77%|███████▋  | 24/31 [00:33<00:09,  1.38s/it, v_num=10, train_loss_step=0.168, train_acc_step=0.936, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  81%|████████  | 25/31 [00:33<00:08,  1.35s/it, v_num=10, train_loss_step=0.168, train_acc_step=0.936, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  81%|████████  | 25/31 [00:34<00:08,  1.38s/it, v_num=10, train_loss_step=0.195, train_acc_step=0.926, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  84%|████████▍ | 26/31 [00:35<00:06,  1.35s/it, v_num=10, train_loss_step=0.195, train_acc_step=0.926, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  84%|████████▍ | 26/31 [00:35<00:06,  1.38s/it, v_num=10, train_loss_step=0.196, train_acc_step=0.930, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  87%|████████▋ | 27/31 [00:36<00:05,  1.35s/it, v_num=10, train_loss_step=0.196, train_acc_step=0.930, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  87%|████████▋ | 27/31 [00:37<00:05,  1.38s/it, v_num=10, train_loss_step=0.162, train_acc_step=0.943, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  90%|█████████ | 28/31 [00:37<00:04,  1.36s/it, v_num=10, train_loss_step=0.162, train_acc_step=0.943, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  90%|█████████ | 28/31 [00:38<00:04,  1.38s/it, v_num=10, train_loss_step=0.214, train_acc_step=0.906, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  94%|█████████▎| 29/31 [00:39<00:02,  1.36s/it, v_num=10, train_loss_step=0.214, train_acc_step=0.906, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  94%|█████████▎| 29/31 [00:39<00:02,  1.38s/it, v_num=10, train_loss_step=0.200, train_acc_step=0.918, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  97%|█████████▋| 30/31 [00:40<00:01,  1.36s/it, v_num=10, train_loss_step=0.200, train_acc_step=0.918, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4:  97%|█████████▋| 30/31 [00:41<00:01,  1.38s/it, v_num=10, train_loss_step=0.196, train_acc_step=0.934, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4: 100%|██████████| 31/31 [00:42<00:00,  1.36s/it, v_num=10, train_loss_step=0.196, train_acc_step=0.934, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]Epoch 4: 100%|██████████| 31/31 [00:42<00:00,  1.38s/it, v_num=10, train_loss_step=0.188, train_acc_step=0.934, val_loss_step=0.247, val_acc_step=0.910, val_loss_epoch=0.222, val_acc_epoch=0.916, train_loss_epoch=0.260, train_acc_epoch=0.904]
Validation: 0it [00:00, ?it/s][A
Validation:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s][A
Validation DataLoader 0:  33%|███▎      | 1/3 [00:00<00:01,  1.95it/s][A
Validation DataLoader 0:  67%|██████▋   | 2/3 [00:01<00:00,  1.92it/s][A
Validation DataLoader 0: 100%|██████████| 3/3 [00:01<00:00,  1.93it/s][AEpoch 4: 100%|██████████| 31/31 [00:44<00:00,  1.43s/it, v_num=10, train_loss_step=0.188, train_acc_step=0.934, val_loss_step=0.168, val_acc_step=0.930, val_loss_epoch=0.180, val_acc_epoch=0.924, train_loss_epoch=0.260, train_acc_epoch=0.904]
`Trainer.fit` stopped: `max_epochs=5` reached.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
SLURM auto-requeueing enabled. Setting signal handlers.
                                                                      [AEpoch 4: 100%|██████████| 31/31 [00:44<00:00,  1.43s/it, v_num=10, train_loss_step=0.188, train_acc_step=0.934, val_loss_step=0.168, val_acc_step=0.930, val_loss_epoch=0.180, val_acc_epoch=0.924, train_loss_epoch=0.196, train_acc_epoch=0.928]Epoch 4: 100%|██████████| 31/31 [00:45<00:00,  1.46s/it, v_num=10, train_loss_step=0.188, train_acc_step=0.934, val_loss_step=0.168, val_acc_step=0.930, val_loss_epoch=0.180, val_acc_epoch=0.924, train_loss_epoch=0.196, train_acc_epoch=0.928]
模型训练成功
**************************************************
开始进行test
/home/jiangyunqi/anaconda3/envs/study-llama-v2-finetune/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:486: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.
  rank_zero_warn(
/home/jiangyunqi/anaconda3/envs/study-llama-v2-finetune/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 72 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Testing: 0it [00:00, ?it/s]Testing:   0%|          | 0/3 [00:00<?, ?it/s]Testing DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]Testing DataLoader 0:  33%|███▎      | 1/3 [00:00<00:01,  1.96it/s]Testing DataLoader 0:  67%|██████▋   | 2/3 [00:01<00:00,  1.94it/s]Testing DataLoader 0: 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]Testing DataLoader 0: 100%|██████████| 3/3 [00:01<00:00,  1.94it/s]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│      test_acc_epoch       │    0.9244791865348816     │
│      test_loss_epoch      │    0.1709325909614563     │
└───────────────────────────┴───────────────────────────┘
这个工作完成啦
